{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:13:08.349674Z",
     "start_time": "2024-12-16T04:13:08.342376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum as spark_sum\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "4601b4c2ca8b1831",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:13:08.915736Z",
     "start_time": "2024-12-16T04:13:08.902726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Restart SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SpamClassifier\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ],
   "id": "3eaa6443e2aecd55",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:13:11.942582Z",
     "start_time": "2024-12-16T04:13:10.015211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = load_dataset(\"SetFit/enron_spam\")\n",
    "\n",
    "df = data[\"train\"]\n",
    "\n",
    "df"
   ],
   "id": "f0a29950cb1585f5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['message_id', 'text', 'label', 'label_text', 'subject', 'message', 'date'],\n",
       "    num_rows: 31716\n",
       "})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:13:14.865534Z",
     "start_time": "2024-12-16T04:13:14.110968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save train and test splits as JSONL\n",
    "df.to_json(\"train.jsonl\", lines=True)"
   ],
   "id": "b68331b29c2aff37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/32 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c9c358cda004157846641d1de2fabf7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "100716400"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:13:16.369398Z",
     "start_time": "2024-12-16T04:13:16.077201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_path = \"train.jsonl\"\n",
    "\n",
    "df = spark.read.json(df_path)"
   ],
   "id": "3393aee4096d661c",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Understanding",
   "id": "69049bf3354fb1e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:13:18.400817Z",
     "start_time": "2024-12-16T04:13:18.243234Z"
    }
   },
   "cell_type": "code",
   "source": "df.show(5)",
   "id": "98ee7905bd5aa873",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+--------------------+----------+--------------------+--------------------+\n",
      "|date|label|label_text|             message|message_id|             subject|                text|\n",
      "+----+-----+----------+--------------------+----------+--------------------+--------------------+\n",
      "|1119|    1|      spam|understanding oem...|     33214|any software just...|any software just...|\n",
      "| 992|    0|       ham|19 th , 2 : 00 pm...|     11929|perspective on fe...|perspective on fe...|\n",
      "|1094|    1|      spam|viagra at $ 1 . 1...|     19784|wanted to try ci ...|wanted to try ci ...|\n",
      "| 976|    0|       ham|teco tap 30 . 000...|      2209|enron / hpl actua...|enron / hpl actua...|\n",
      "|1108|    1|      spam|water past also ,...|     15880|looking for cheap...|looking for cheap...|\n",
      "+----+-----+----------+--------------------+----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:13:19.372495Z",
     "start_time": "2024-12-16T04:13:19.359221Z"
    }
   },
   "cell_type": "code",
   "source": "df.printSchema()",
   "id": "6e748838d69b8026",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: long (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      " |-- label_text: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- message_id: long (nullable = true)\n",
      " |-- subject: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:13:21.255880Z",
     "start_time": "2024-12-16T04:13:21.218633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Drop unnecessary columns\n",
    "df = df.drop('text', 'label_text','date')"
   ],
   "id": "991fb20d7ba5d32a",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:13:29.203163Z",
     "start_time": "2024-12-16T04:13:28.571357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check Nulls\n",
    "null_counts_df = df.select(\n",
    "    *[ spark_sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns ]\n",
    ")\n",
    "\n",
    "null_counts_df.show()"
   ],
   "id": "ad3f2009db0dd3ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+----------+-------+\n",
      "|label|message|message_id|subject|\n",
      "+-----+-------+----------+-------+\n",
      "|    0|      0|         0|      0|\n",
      "+-----+-------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Cleaning",
   "id": "569ce2080be6dbe0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:13:31.513203Z",
     "start_time": "2024-12-16T04:13:31.500404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import string\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType\n",
    "import spacy\n",
    "import inflect\n",
    "from nltk.corpus import stopwords"
   ],
   "id": "bc492d870963beef",
   "outputs": [],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:13:31.955480Z",
     "start_time": "2024-12-16T04:13:31.942181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TextCleaner:\n",
    "    def __init__(self, subject_col: str, message_col: str, remove_stopwords=True):\n",
    "        self.subject_col = subject_col\n",
    "        self.message_col = message_col\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.stop_words = set(stopwords.words('english')) if remove_stopwords else None\n",
    "        self.inflector = inflect.engine() \n",
    "        self.nlp = spacy.load('en_core_web_sm', disable=[\"ner\", \"parser\"])  # Load spaCy model for lemmatization\n",
    "\n",
    "    # Cleans a single text string \n",
    "    def clean_text(self, text: str) -> str:\n",
    "        # Handle non-string values gracefully\n",
    "        if not isinstance(text, str):  \n",
    "            return str(text) if text is not None else \"\"\n",
    "\n",
    "        # Lowercase the text\n",
    "        text = text.lower()\n",
    "\n",
    "        # Remove URLs\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '<URL>', text)\n",
    "\n",
    "        # Remove email addresses\n",
    "        text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '<EMAIL>', text)\n",
    "\n",
    "        # Remove HTML tags using regex\n",
    "        text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "        # Replace $ with 'dollar'\n",
    "        text = text.replace('$', 'dollar')\n",
    "\n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        # Convert numbers to words\n",
    "        text = ' '.join([self.inflector.number_to_words(word) if word.isdigit() else word for word in text.split()])\n",
    "\n",
    "        # Remove extra whitespaces\n",
    "        text = ' '.join(text.split())\n",
    "\n",
    "        return text\n",
    "\n",
    "    # Tokenizes and lemmatizes the text using spaCy\n",
    "    def lemmatize_text(self, text: str) -> str:\n",
    "\n",
    "        doc = self.nlp(text)\n",
    "        tokens = [token.lemma_ for token in doc]  # Lemmatized tokens\n",
    "\n",
    "        # Remove stop words (optional)\n",
    "        if self.remove_stopwords:\n",
    "            tokens = [word for word in tokens if word not in self.stop_words]\n",
    "\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    # Cleans the specified columns of the Spark DataFrame.\n",
    "    def clean_dataframe(self, df):\n",
    "        # Define UDFs\n",
    "        clean_text_udf = udf(self.clean_text, StringType())\n",
    "        lemmatize_text_udf = udf(self.lemmatize_text, StringType())\n",
    "\n",
    "        # Apply UDFs to clean and lemmatize columns\n",
    "        df = df.withColumn(self.subject_col, clean_text_udf(col(self.subject_col)))\n",
    "        df = df.withColumn(self.message_col, clean_text_udf(col(self.message_col)))\n",
    "        df = df.withColumn(f'{self.subject_col}_lem_tokens', lemmatize_text_udf(col(self.subject_col)))\n",
    "        df = df.withColumn(f'{self.message_col}_lem_tokens', lemmatize_text_udf(col(self.message_col)))\n",
    "\n",
    "        return df"
   ],
   "id": "b44b4e6588a9ccad",
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:13:33.131074Z",
     "start_time": "2024-12-16T04:13:32.330276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize TextCleaner\n",
    "cleaner = TextCleaner(subject_col=\"subject\", message_col=\"message\", remove_stopwords=True)\n",
    "\n",
    "# Clean datasets\n",
    "cleaned_df = cleaner.clean_dataframe(df)"
   ],
   "id": "446135bd1344f898",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:13:37.891073Z",
     "start_time": "2024-12-16T04:13:33.729713Z"
    }
   },
   "cell_type": "code",
   "source": "cleaned_df.show(5)",
   "id": "1e02dff1dc83010",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "|label|             message|message_id|             subject|  subject_lem_tokens|  message_lem_tokens|\n",
      "+-----+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "|    1|understanding oem...|     33214|any software just...|software fifteen ...|understand oem so...|\n",
      "|    0|nineteen th two z...|     11929|perspective on fe...|perspective ferc ...|nineteen th two z...|\n",
      "|    1|viagra at dollar ...|     19784|wanted to try ci ...|want try ci four ...|viagra dollar one...|\n",
      "|    0|teco tap thirty z...|      2209|enron hpl actuals...|enron hpl actual ...|teco tap thirty z...|\n",
      "|    1|water past also b...|     15880|looking for cheap...|look cheap high q...|water past also b...|\n",
      "+-----+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Processing",
   "id": "4f3e5d7f0c7b5206"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:13:37.908281Z",
     "start_time": "2024-12-16T04:13:37.899214Z"
    }
   },
   "cell_type": "code",
   "source": "from pyspark.ml.feature import Tokenizer, CountVectorizer, IDF",
   "id": "6f6fe0ade485c96b",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:13:38.921489Z",
     "start_time": "2024-12-16T04:13:38.909761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeatureExtraction:\n",
    "    def __init__(self, subject_col: str, message_col: str, ngram_range=(1, 2), max_features=1000):\n",
    "\n",
    "        self.subject_col = subject_col\n",
    "        self.message_col = message_col\n",
    "        self.ngram_range = ngram_range\n",
    "        self.max_features = max_features\n",
    "\n",
    "        # TF-IDF components for subject\n",
    "        self.subject_tokenizer = Tokenizer(inputCol=self.subject_col, outputCol=f\"{self.subject_col}_tokens\")\n",
    "        self.subject_vectorizer = CountVectorizer(inputCol=f\"{self.subject_col}_tokens\",\n",
    "                                                  outputCol=f\"{self.subject_col}_raw_features\",\n",
    "                                                  vocabSize=self.max_features)\n",
    "        self.subject_idf = IDF(inputCol=f\"{self.subject_col}_raw_features\", outputCol=f\"{self.subject_col}_features\")\n",
    "\n",
    "        # TF-IDF components for message\n",
    "        self.message_tokenizer = Tokenizer(inputCol=self.message_col, outputCol=f\"{self.message_col}_tokens\")\n",
    "        self.message_vectorizer = CountVectorizer(inputCol=f\"{self.message_col}_tokens\",\n",
    "                                                  outputCol=f\"{self.message_col}_raw_features\",\n",
    "                                                  vocabSize=self.max_features)\n",
    "        self.message_idf = IDF(inputCol=f\"{self.message_col}_raw_features\", outputCol=f\"{self.message_col}_features\")\n",
    "\n",
    "    # Fit TF-IDF vectorizers to the data and add transformed features as new columns.\n",
    "    def fit_transform(self, df):\n",
    "        # Tokenize subject and message columns\n",
    "        df = self.subject_tokenizer.transform(df)\n",
    "        df = self.message_tokenizer.transform(df)\n",
    "\n",
    "        # Fit and transform subject TF-IDF\n",
    "        subject_cv_model = self.subject_vectorizer.fit(df)\n",
    "        df = subject_cv_model.transform(df)\n",
    "        subject_idf_model = self.subject_idf.fit(df)\n",
    "        df = subject_idf_model.transform(df)\n",
    "\n",
    "        # Fit and transform message TF-IDF\n",
    "        message_cv_model = self.message_vectorizer.fit(df)\n",
    "        df = message_cv_model.transform(df)\n",
    "        message_idf_model = self.message_idf.fit(df)\n",
    "        df = message_idf_model.transform(df)\n",
    "\n",
    "        return df\n",
    "\n",
    "    # Transform new data using the already fitted TF-IDF vectorizers and add features as columns.\n",
    "    def transform(self, df):\n",
    "        # Tokenize subject and message columns\n",
    "        df = self.subject_tokenizer.transform(df)\n",
    "        df = self.message_tokenizer.transform(df)\n",
    "\n",
    "        # Transform subject TF-IDF\n",
    "        df = self.subject_vectorizer.transform(df)\n",
    "        df = self.subject_idf.transform(df)\n",
    "\n",
    "        # Transform message TF-IDF\n",
    "        df = self.message_vectorizer.transform(df)\n",
    "        df = self.message_idf.transform(df)\n",
    "\n",
    "        return df"
   ],
   "id": "e3311116b9a8e75b",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:13:39.708521Z",
     "start_time": "2024-12-16T04:13:39.690966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_extractor = FeatureExtraction(subject_col=\"subject_lem_tokens\",\n",
    "                                      message_col=\"message_lem_tokens\",\n",
    "                                      ngram_range=(1, 2),\n",
    "                                      max_features=1000)"
   ],
   "id": "74a366c028d6569",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:17:41.293127Z",
     "start_time": "2024-12-16T04:13:40.153201Z"
    }
   },
   "cell_type": "code",
   "source": "feature_extracted_df = feature_extractor.fit_transform(cleaned_df)",
   "id": "71a20df6d9510120",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:17:47.324211Z",
     "start_time": "2024-12-16T04:17:41.308423Z"
    }
   },
   "cell_type": "code",
   "source": "feature_extracted_df.show(5)",
   "id": "bd44b7d606a480a1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3292:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+--------------------+--------------------+--------------------+-------------------------+-------------------------+-------------------------------+---------------------------+-------------------------------+---------------------------+\n",
      "|label|             message|message_id|             subject|  subject_lem_tokens|  message_lem_tokens|subject_lem_tokens_tokens|message_lem_tokens_tokens|subject_lem_tokens_raw_features|subject_lem_tokens_features|message_lem_tokens_raw_features|message_lem_tokens_features|\n",
      "+-----+--------------------+----------+--------------------+--------------------+--------------------+-------------------------+-------------------------+-------------------------------+---------------------------+-------------------------------+---------------------------+\n",
      "|    1|understanding oem...|     33214|any software just...|software fifteen ...|understand oem so...|     [software, fiftee...|     [understand, oem,...|           (1000,[0,8,15,21,...|       (1000,[0,8,15,21,...|           (1000,[0,1,4,5,6,...|       (1000,[0,1,4,5,6,...|\n",
      "|    0|nineteen th two z...|     11929|perspective on fe...|perspective ferc ...|nineteen th two z...|     [perspective, fer...|     [nineteen, th, tw...|           (1000,[46,110,127...|       (1000,[46,110,127...|           (1000,[0,1,2,3,4,...|       (1000,[0,1,2,3,4,...|\n",
      "|    1|viagra at dollar ...|     19784|wanted to try ci ...|want try ci four ...|viagra dollar one...|     [want, try, ci, f...|     [viagra, dollar, ...|           (1000,[12,60,257,...|       (1000,[12,60,257,...|           (1000,[2,12,34,38...|       (1000,[2,12,34,38...|\n",
      "|    0|teco tap thirty z...|      2209|enron hpl actuals...|enron hpl actual ...|teco tap thirty z...|     [enron, hpl, actu...|     [teco, tap, thirt...|           (1000,[1,3,13,31,...|       (1000,[1,3,13,31,...|           (1000,[1,2,7,10,1...|       (1000,[1,2,7,10,1...|\n",
      "|    1|water past also b...|     15880|looking for cheap...|look cheap high q...|water past also b...|     [look, cheap, hig...|     [water, past, als...|           (1000,[21,43,92,1...|       (1000,[21,43,92,1...|           (1000,[68,78,94,1...|       (1000,[68,78,94,1...|\n",
      "+-----+--------------------+----------+--------------------+--------------------+--------------------+-------------------------+-------------------------+-------------------------------+---------------------------+-------------------------------+---------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:17:47.357207Z",
     "start_time": "2024-12-16T04:17:47.328752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "selected_columns = [\"subject_lem_tokens_features\", \"message_lem_tokens_features\", \"label\"]\n",
    "df_for_model = feature_extracted_df.select(*selected_columns)"
   ],
   "id": "6f25809cf5e7746b",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### EDA",
   "id": "128f342735877861"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:17:47.369800Z",
     "start_time": "2024-12-16T04:17:47.359730Z"
    }
   },
   "cell_type": "code",
   "source": "from pyspark.sql.functions import explode, split, col",
   "id": "f4de2c21e79a6b2f",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:50:25.466524Z",
     "start_time": "2024-12-16T04:50:23.634182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count spam and ham emails\n",
    "feature_extracted_df.groupBy(\"label\").count().show()"
   ],
   "id": "b05db74665c49f77",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3350:>                                                       (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|15553|\n",
      "|    1|16163|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:50:51.839819Z",
     "start_time": "2024-12-16T04:50:25.476027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create and apply tokenizer to the subject column\n",
    "tokenizer = Tokenizer(inputCol=\"subject\", outputCol=\"subject_tokens\")\n",
    "tokenized_df = tokenizer.transform(feature_extracted_df)\n",
    "\n",
    "# Now split and explode the tokens\n",
    "words = tokenized_df.withColumn(\"word\", explode(col(\"subject_tokens\")))\n",
    "\n",
    "# Count unique words\n",
    "unique_word_count = words.select(\"word\").distinct().count()\n",
    "print(f\"Total number of unique words in subject: {unique_word_count}\")\n",
    "\n",
    "# Analyze spam words (label == 1)\n",
    "spam_words = words.filter(col(\"label\") == 1).groupBy(\"word\").count().orderBy(col(\"count\").desc())\n",
    "spam_words.show(10, truncate=False)\n",
    "\n",
    "# Analyze ham words (label == 0)\n",
    "ham_words = words.filter(col(\"label\") == 0).groupBy(\"word\").count().orderBy(col(\"count\").desc())\n",
    "ham_words.show(10, truncate=False)"
   ],
   "id": "f26d4270b7993adb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words in subject: 16247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|word   |count|\n",
      "+-------+-----+\n",
      "|and    |2501 |\n",
      "|your   |1997 |\n",
      "|you    |1744 |\n",
      "|hundred|1535 |\n",
      "|to     |1500 |\n",
      "|the    |1444 |\n",
      "|for    |1441 |\n",
      "|a      |1200 |\n",
      "|one    |1000 |\n",
      "|dollar |973  |\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3362:=====================>                                  (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|word    |count|\n",
      "+--------+-----+\n",
      "|re      |3712 |\n",
      "|and     |2407 |\n",
      "|two     |2284 |\n",
      "|one     |2105 |\n",
      "|for     |1959 |\n",
      "|thousand|1409 |\n",
      "|fw      |1176 |\n",
      "|enron   |1064 |\n",
      "|hundred |931  |\n",
      "|to      |750  |\n",
      "+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:51:50.546522Z",
     "start_time": "2024-12-16T04:50:51.915549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create and apply tokenizer to the message column\n",
    "tokenizer = Tokenizer(inputCol=\"message\", outputCol=\"message_tokens\")\n",
    "tokenized_df = tokenizer.transform(feature_extracted_df)\n",
    "\n",
    "# Now split and explode the tokens\n",
    "words = tokenized_df.withColumn(\"word\", explode(col(\"message_tokens\")))\n",
    "\n",
    "# Count unique words\n",
    "unique_word_count = words.select(\"word\").distinct().count()\n",
    "print(f\"Total number of unique words in subject: {unique_word_count}\")\n",
    "\n",
    "\n",
    "# Analyze spam words (label == 1)\n",
    "print(f\"Most used words in spam emails\")\n",
    "spam_words = words.filter(col(\"label\") == 1).groupBy(\"word\").count().orderBy(col(\"count\").desc())\n",
    "spam_words.show(10, truncate=False)\n",
    "\n",
    "# Analyze ham words (label == 0)\n",
    "print(f\"Most used words in non-spam emails\")\n",
    "ham_words = words.filter(col(\"label\") == 0).groupBy(\"word\").count().orderBy(col(\"count\").desc())\n",
    "ham_words.show(10, truncate=False)"
   ],
   "id": "ce9a5927f170950a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words in subject: 137524\n",
      "Most used words in spam emails\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|word   |count |\n",
      "+-------+------+\n",
      "|and    |118166|\n",
      "|the    |101457|\n",
      "|to     |77349 |\n",
      "|of     |66602 |\n",
      "|a      |48627 |\n",
      "|hundred|48291 |\n",
      "|you    |43171 |\n",
      "|in     |43021 |\n",
      "|one    |33661 |\n",
      "|this   |32494 |\n",
      "+-------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Most used words in non-spam emails\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3374:============================>                           (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|word   |count |\n",
      "+-------+------+\n",
      "|the    |170997|\n",
      "|and    |150786|\n",
      "|to     |121485|\n",
      "|of     |72201 |\n",
      "|hundred|61400 |\n",
      "|a      |61196 |\n",
      "|two    |58535 |\n",
      "|in     |56734 |\n",
      "|enron  |55656 |\n",
      "|one    |54259 |\n",
      "+-------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Modelling",
   "id": "da6de279c02a9adf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T02:17:21.796470Z",
     "start_time": "2024-12-16T02:17:21.770055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import NaiveBayes, LogisticRegression, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import pandas as pd"
   ],
   "id": "28faa71417a0b2a0",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T02:17:22.647956Z",
     "start_time": "2024-12-16T02:17:22.602146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SparkSpamClassifier:\n",
    "    def __init__(self, label_col, feature_cols, test_size=0.2, seed=42):\n",
    "        self.label_col = label_col\n",
    "        self.feature_cols = feature_cols\n",
    "        self.test_size = test_size\n",
    "        self.seed = seed\n",
    "\n",
    "        # Initialize classifiers\n",
    "        self.models = {\n",
    "            \"NaiveBayes\": NaiveBayes(featuresCol=\"features\", labelCol=self.label_col),\n",
    "            \"LogisticRegression\": LogisticRegression(featuresCol=\"features\", labelCol=self.label_col, maxIter=100),\n",
    "            \"GradientBoostedTrees\": GBTClassifier(featuresCol=\"features\", labelCol=self.label_col)\n",
    "        }\n",
    "        self.trained_models = {}\n",
    "\n",
    "    # Combine multiple feature columns into a single vector column.\n",
    "    def combine_features(self, df):\n",
    "        assembler = VectorAssembler(inputCols=self.feature_cols, outputCol=\"features\")\n",
    "        return assembler.transform(df)\n",
    "\n",
    "    # Split the DataFrame into training and testing sets.\n",
    "    def train_test_split(self, df):\n",
    "        train_df, test_df = df.randomSplit([1 - self.test_size, self.test_size], seed=self.seed)\n",
    "        print(f\"Training data: {train_df.count()} rows, Test data: {test_df.count()} rows\")\n",
    "        return train_df, test_df\n",
    "    \n",
    "    # Train all models on the training data.\n",
    "    def train(self, train_df):\n",
    "        for model_name, model in self.models.items():\n",
    "            print(f\"Training {model_name}...\")\n",
    "            trained_model = model.fit(train_df)\n",
    "            self.trained_models[model_name] = trained_model\n",
    "        print(\"Training complete!\")\n",
    "\n",
    "    # Evaluate all trained models on the test data.\n",
    "    def evaluate(self, test_df, mode='summary'):\n",
    "        evaluator = MulticlassClassificationEvaluator(labelCol=self.label_col, predictionCol=\"prediction\")\n",
    "        results = {}\n",
    "\n",
    "        for model_name, trained_model in self.trained_models.items():\n",
    "            print(f\"Evaluating {model_name}...\")\n",
    "            predictions = trained_model.transform(test_df)\n",
    "            \n",
    "            # Compute metrics\n",
    "            accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "            precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "            recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "            f1 = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "            \n",
    "            metrics = {\n",
    "                \"predictions\": predictions,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"f1_score\": f1\n",
    "            }\n",
    "            results[model_name] = metrics\n",
    "\n",
    "        # Create a summary DataFrame\n",
    "        if mode == 'summary':\n",
    "            summary_data = {\n",
    "                \"Model\": [],\n",
    "                \"Accuracy\": [],\n",
    "                \"Precision\": [],\n",
    "                \"Recall\": [],\n",
    "                \"F1 Score\": []\n",
    "            }\n",
    "            for model_name, metrics in results.items():\n",
    "                summary_data[\"Model\"].append(model_name)\n",
    "                summary_data[\"Accuracy\"].append(metrics[\"accuracy\"])\n",
    "                summary_data[\"Precision\"].append(metrics[\"precision\"])\n",
    "                summary_data[\"Recall\"].append(metrics[\"recall\"])\n",
    "                summary_data[\"F1 Score\"].append(metrics[\"f1_score\"])\n",
    "\n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            return summary_df\n",
    "\n",
    "        elif mode == 'details':\n",
    "            for model_name, metrics in results.items():\n",
    "                print(\"-\" * 50)\n",
    "                print(f\"{model_name} - Metrics:\")\n",
    "                print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
    "                print(f\"  Precision: {metrics['precision']:.4f}\")\n",
    "                print(f\"  Recall: {metrics['recall']:.4f}\")\n",
    "                print(f\"  F1 Score: {metrics['f1_score']:.4f}\")\n",
    "                print(f\"  Predictions Schema: {metrics['predictions'].schema}\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode. Use 'summary' or 'details'.\")\n",
    "\n",
    "        return results"
   ],
   "id": "f6a8fe5dabc4c410",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T02:17:24.905682Z",
     "start_time": "2024-12-16T02:17:24.708797Z"
    }
   },
   "cell_type": "code",
   "source": "classifier = SparkSpamClassifier(label_col=\"label\", feature_cols=[\"subject_lem_tokens_features\", \"message_lem_tokens_features\"])",
   "id": "bfdf912e876e53e7",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T02:18:04.026736Z",
     "start_time": "2024-12-16T02:18:03.409079Z"
    }
   },
   "cell_type": "code",
   "source": "combined_df = classifier.combine_features(df_for_model)",
   "id": "82cb7701da902b3d",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T02:24:14.723332Z",
     "start_time": "2024-12-16T02:18:05.866491Z"
    }
   },
   "cell_type": "code",
   "source": "train_df, test_df = classifier.train_test_split(combined_df)",
   "id": "1050d3483c3c03a7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2805:=================================================>      (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 25524 rows, Test data: 6192 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T02:55:57.387311Z",
     "start_time": "2024-12-16T02:26:28.646106Z"
    }
   },
   "cell_type": "code",
   "source": "classifier.train(train_df)",
   "id": "b55cfb21e5a089d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NaiveBayes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GradientBoostedTrees...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation",
   "id": "df62a527873d41bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:47:22.280810Z",
     "start_time": "2024-12-16T02:55:57.410612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate models on the test data\n",
    "summary = classifier.evaluate(test_df, mode=\"summary\")\n",
    "print(summary)"
   ],
   "id": "5b2c4bd55fecc30c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating NaiveBayes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LogisticRegression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating GradientBoostedTrees...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mammadovzulfugar/Documents/ADA_University/Big_Data/BigData_Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Model  Accuracy  Precision    Recall  F1 Score\n",
      "0            NaiveBayes  0.968831   0.969180  0.968831  0.968823\n",
      "1    LogisticRegression  0.971738   0.971745  0.971738  0.971737\n",
      "2  GradientBoostedTrees  0.921996   0.928939  0.921996  0.921653\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T00:15:24.258158Z",
     "start_time": "2024-12-14T00:15:23.904616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# More detailed result\n",
    "classifier.evaluate(test_df, mode='details')"
   ],
   "id": "96112c05f788d838",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MultinomialNB...\n",
      "Evaluating LogisticRegression...\n",
      "Evaluating LightGBM...\n",
      "--------------------------------------------------\n",
      "\n",
      "MultinomialNB - Confusion Matrix:\n",
      "[[2960  124]\n",
      " [  99 3161]]\n",
      "\n",
      "MultinomialNB - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      3084\n",
      "           1       0.97      0.99      0.98      3260\n",
      "\n",
      "    accuracy                           0.98      6344\n",
      "   macro avg       0.98      0.98      0.98      6344\n",
      "weighted avg       0.98      0.98      0.98      6344\n",
      "\n",
      "MultinomialNB - Accuracy Score: 0.96\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "LogisticRegression - Confusion Matrix:\n",
      "[[2983  101]\n",
      " [  37 3223]]\n",
      "\n",
      "LogisticRegression - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      3084\n",
      "           1       0.97      0.99      0.98      3260\n",
      "\n",
      "    accuracy                           0.98      6344\n",
      "   macro avg       0.98      0.98      0.98      6344\n",
      "weighted avg       0.98      0.98      0.98      6344\n",
      "\n",
      "LogisticRegression - Accuracy Score: 0.98\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "LightGBM - Confusion Matrix:\n",
      "[[2974  110]\n",
      " [  28 3232]]\n",
      "\n",
      "LightGBM - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      3084\n",
      "           1       0.97      0.99      0.98      3260\n",
      "\n",
      "    accuracy                           0.98      6344\n",
      "   macro avg       0.98      0.98      0.98      6344\n",
      "weighted avg       0.98      0.98      0.98      6344\n",
      "\n",
      "LightGBM - Accuracy Score: 0.98\n",
      "\n"
     ]
    }
   ],
   "execution_count": 221
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
